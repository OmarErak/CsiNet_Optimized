{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "import os\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "import scipy.io as sio \n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "envir = 'outdoor' #'indoor' or 'outdoor'\n",
    "# image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2 \n",
    "img_total = img_height*img_width*img_channels\n",
    "# network params\n",
    "residual_num = 2\n",
    "encoded_dim = 32 #compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "if envir == 'indoor':\n",
    "    mat = sio.loadmat('data/DATA_Htrainin.mat') \n",
    "    x_train = mat['HT'] # array\n",
    "    mat = sio.loadmat('data/DATA_Hvalin.mat')\n",
    "    x_val = mat['HT'] # array\n",
    "    mat = sio.loadmat('data/DATA_Htestin.mat')\n",
    "    x_test = mat['HT'] # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "    mat = sio.loadmat('data/DATA_Htrainout.mat') \n",
    "    x_train = mat['HT'] # array\n",
    "    mat = sio.loadmat('data/DATA_Hvalout.mat')\n",
    "    x_val = mat['HT'] # array\n",
    "    mat = sio.loadmat('data/DATA_Htestout.mat')\n",
    "    x_test = mat['HT'] # array\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = np.reshape(x_train, (len(x_train), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_val = np.reshape(x_val, (len(x_val), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base model from disk\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2, 32, 32)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 2, 32, 32)    38          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 2, 32, 32)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2048)         0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           65568       ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2048)         67584       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 2, 32, 32)    0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 32, 32)    152         ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2, 32, 32)    0           ['reshape_2[0][0]',              \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 32, 32)    152         ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 32, 32)    0           ['leaky_re_lu_4[0][0]',          \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 2, 32, 32)    38          ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 137,344\n",
      "Trainable params: 136,896\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file = 'CsiNet_'+(envir)+'_dim'+str(encoded_dim)\n",
    "json_file = open('saved_model/model_%s.json'%file, 'r')\n",
    "base_model_json = json_file.read()\n",
    "json_file.close()\n",
    "base_model = model_from_json(base_model_json)\n",
    "# load weights into new model\n",
    "base_model.load_weights(\"saved_model/model_%s.h5\"%file)\n",
    "print(\"Loaded base model from disk\")\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2, 32, 32)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 2, 32, 32)    38          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_1[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 2, 32, 32)    0           ['batch_normalization_1[1][0]']  \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2048)         0           ['leaky_re_lu_1[1][0]']          \n",
      "                                                                                                  \n",
      " cluster_dense_1 (ClusterWeight  (None, 32)          131136      ['reshape_1[1][0]']              \n",
      " s)                                                                                               \n",
      "                                                                                                  \n",
      " cluster_dense_2 (ClusterWeight  (None, 2048)        133152      ['cluster_dense_1[0][0]']        \n",
      " s)                                                                                               \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 2, 32, 32)    0           ['cluster_dense_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 32, 32)    152         ['reshape_2[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_2[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_2[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_2[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_3[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_3[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_3[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_4[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2, 32, 32)    0           ['reshape_2[1][0]',              \n",
      "                                                                  'batch_normalization_4[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_1[1][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 32, 32)    152         ['leaky_re_lu_4[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_5[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_5[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_5[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_6[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_6[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_6[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_7[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 32, 32)    0           ['leaky_re_lu_4[1][0]',          \n",
      "                                                                  'batch_normalization_7[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_2[1][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 2, 32, 32)    38          ['leaky_re_lu_7[1][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 268,480\n",
      "Trainable params: 136,960\n",
      "Non-trainable params: 131,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cluster_weights = tfmot.clustering.keras.cluster_weights\n",
    "CentroidInitialization = tfmot.clustering.keras.CentroidInitialization\n",
    "\n",
    "clustering_params = {\n",
    "  'number_of_clusters': 32,\n",
    "  'cluster_centroids_init': CentroidInitialization.KMEANS_PLUS_PLUS\n",
    "}\n",
    "\n",
    "# Helper function uses `cluster_weights` to make only \n",
    "# the Dense layers train with clustering\n",
    "def apply_clustering_to_dense(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return cluster_weights(layer, **clustering_params)\n",
    "  return layer\n",
    "\n",
    "# Use `tf.keras.models.clone_model` to apply `apply_clustering_to_dense` \n",
    "# to the layers of the model.\n",
    "clustered_model = tf.keras.models.clone_model(\n",
    "    base_model,\n",
    "    clone_function=apply_clustering_to_dense,\n",
    ")\n",
    "\n",
    "clustered_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "clustered_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "500/500 [==============================] - 27s 41ms/step - loss: 5.3805e-04 - val_loss: 5.4318e-04\n",
      "Epoch 2/8\n",
      "500/500 [==============================] - 18s 35ms/step - loss: 5.3724e-04 - val_loss: 5.3727e-04\n",
      "Epoch 3/8\n",
      "500/500 [==============================] - 18s 36ms/step - loss: 5.3775e-04 - val_loss: 5.3756e-04\n",
      "Epoch 4/8\n",
      "500/500 [==============================] - 19s 37ms/step - loss: 5.3755e-04 - val_loss: 5.3829e-04\n",
      "Epoch 5/8\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 5.3744e-04 - val_loss: 5.4352e-04\n",
      "Epoch 6/8\n",
      "500/500 [==============================] - 21s 42ms/step - loss: 5.3717e-04 - val_loss: 5.3641e-04\n",
      "Epoch 7/8\n",
      "500/500 [==============================] - 23s 45ms/step - loss: 5.3697e-04 - val_loss: 5.4215e-04\n",
      "Epoch 8/8\n",
      "500/500 [==============================] - 24s 48ms/step - loss: 5.3687e-04 - val_loss: 5.3769e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f38175a620>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_model.fit(x_train, x_train,\n",
    "                epochs=8,\n",
    "                batch_size=200,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = tfmot.clustering.keras.strip_clustering(clustered_model)\n",
    "file = (envir)+'_dim'+str(encoded_dim)\n",
    "# clustered_keras_file = ('omar_saved_model/clustered_model.h5')\n",
    "# tf.keras.models.save_model(final_model, clustered_keras_file, include_optimizer=False)\n",
    "# print('Saved clustered Keras model to:', clustered_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpfo3icekz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpfo3icekz\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "clustered_tflite_model = converter.convert()\n",
    "\n",
    "# Saving the model.\n",
    "with open('optimized_models/%s/clustered_model_%s.tflite'%(file, file), 'wb') as f:\n",
    "  f.write(clustered_tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # It returns the size of the gzipped model in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustered model in Mb: 0.13439369201660156\n"
     ]
    }
   ],
   "source": [
    "file = (envir)+'_dim'+str(encoded_dim)\n",
    "clustered_size = (get_gzipped_model_size('optimized_models/%s/clustered_model_%s.tflite'%(file, file)))\n",
    "print(\"clustered model in Mb:\", clustered_size / float(2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpw8tst0e4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpw8tst0e4\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpjd07d07e\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpjd07d07e\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Passing the Keras model to the TF Lite Converter.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "# Using float-16 quantization.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "# Converting the model.\n",
    "clustered_fp16_quantized_tflite_model = converter.convert()\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(final_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_clustered_tflite_model = converter.convert()\n",
    "\n",
    "# Saving the model.\n",
    "with open('optimized_models/%s/clustered_quant_model_%s.tflite'%(file, file), 'wb') as f:\n",
    "  f.write(quantized_and_clustered_tflite_model)\n",
    "with open('optimized_models/%s/clustered_fp16_quant_model_%s.tflite'%(file, file), 'wb') as f:\n",
    "  f.write(clustered_fp16_quantized_tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned quant model in Mb: 0.10184097290039062\n"
     ]
    }
   ],
   "source": [
    "prune_quant_size = (get_gzipped_model_size('optimized_models/%s/clustered_quant_model_%s.tflite'%(file, file)))\n",
    "prune_fp16_quant_size = (get_gzipped_model_size('optimized_models/%s/clustered_fp16_quant_model_%s.tflite'%(file, file)))\n",
    "print(\"pruned quant model in Mb:\", prune_quant_size / float(2**20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "946bca45cd194ef20b20aa2df2b6857f6c4def631856f59c9b0da3a792eb3375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
