{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, BatchNormalization, Reshape, Conv2D, add, LeakyReLU\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.callbacks import TensorBoard, Callback\n",
    "import scipy.io as sio \n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "envir = 'indoor' #'indoor' or 'outdoor'\n",
    "# image params\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 2 \n",
    "img_total = img_height*img_width*img_channels\n",
    "# network params\n",
    "residual_num = 2\n",
    "encoded_dim = 512 #compress rate=1/4->dim.=512, compress rate=1/16->dim.=128, compress rate=1/32->dim.=64, compress rate=1/64->dim.=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "if envir == 'indoor':\n",
    "    mat = sio.loadmat('data/DATA_Htrainin.mat') \n",
    "    x_train = mat['HT'] # array\n",
    "    mat = sio.loadmat('data/DATA_Hvalin.mat')\n",
    "    x_val = mat['HT'] # array\n",
    "    mat = sio.loadmat('data/DATA_Htestin.mat')\n",
    "    x_test = mat['HT'] # array\n",
    "\n",
    "elif envir == 'outdoor':\n",
    "    mat = sio.loadmat('data/DATA_Htrainout.mat') \n",
    "    x_train = mat['HT'] # array\n",
    "    mat = sio.loadmat('data/DATA_Hvalout.mat')\n",
    "    x_val = mat['HT'] # array\n",
    "    mat = sio.loadmat('data/DATA_Htestout.mat')\n",
    "    x_test = mat['HT'] # array\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = np.reshape(x_train, (len(x_train), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_val = np.reshape(x_val, (len(x_val), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), img_channels, img_height, img_width))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded base model from disk\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2, 32, 32)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 2, 32, 32)    38          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 2, 32, 32)    0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2048)         0           ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          1049088     ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2048)         1050624     ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 2, 32, 32)    0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 32, 32)    152         ['reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2, 32, 32)    0           ['reshape_2[0][0]',              \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 32, 32)    152         ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 32, 32)    0           ['leaky_re_lu_4[0][0]',          \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 2, 32, 32)    38          ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,103,904\n",
      "Trainable params: 2,103,456\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "file = 'CsiNet_'+(envir)+'_dim'+str(encoded_dim)\n",
    "json_file = open('saved_model/model_%s.json'%file, 'r')\n",
    "base_model_json = json_file.read()\n",
    "json_file.close()\n",
    "base_model = model_from_json(base_model_json)\n",
    "# load weights into new model\n",
    "base_model.load_weights(\"saved_model/model_%s.h5\"%file)\n",
    "print(\"Loaded base model from disk\")\n",
    "base_model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clone_fn(layer):\n",
    "#     if layer.name == 'conv2d_2' or 'conv2d_3' or 'conv2d_4':\n",
    "#         # The default padding `SAME` for the first convolution is incompatible\n",
    "#         # with XNNPACK sparse inference.\n",
    "#         layer.padding = 'valid'\n",
    "#         layer.kernel_size=(1,1)\n",
    "#         # We ask the model to rebuild since we've changed the padding parameter.\n",
    "#         layer.built = False\n",
    "#     return layer\n",
    "\n",
    "# a = tf.keras.models.clone_model(base_model, clone_function=clone_fn)\n",
    "# a.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 2, 32, 32)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 2, 32, 32)    38          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_1[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 2, 32, 32)    0           ['batch_normalization_1[1][0]']  \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2048)         0           ['leaky_re_lu_1[1][0]']          \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_1 (P  (None, 512)         2097666     ['reshape_1[1][0]']              \n",
      " runeLowMagnitude)                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_2 (P  (None, 2048)        2099202     ['prune_low_magnitude_dense_1[0][\n",
      " runeLowMagnitude)                                               0]']                             \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 2, 32, 32)    0           ['prune_low_magnitude_dense_2[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 8, 32, 32)    152         ['reshape_2[1][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_2[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_2[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_2[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_3[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_3[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_3[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_4[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 2, 32, 32)    0           ['reshape_2[1][0]',              \n",
      "                                                                  'batch_normalization_4[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_1[1][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 8, 32, 32)    152         ['leaky_re_lu_4[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 8, 32, 32)   128         ['conv2d_5[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 8, 32, 32)    0           ['batch_normalization_5[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 16, 32, 32)   1168        ['leaky_re_lu_5[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 32, 32)  128         ['conv2d_6[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 16, 32, 32)   0           ['batch_normalization_6[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 2, 32, 32)    290         ['leaky_re_lu_6[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2, 32, 32)   128         ['conv2d_7[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 2, 32, 32)    0           ['leaky_re_lu_4[1][0]',          \n",
      "                                                                  'batch_normalization_7[1][0]']  \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 2, 32, 32)    0           ['add_2[1][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 2, 32, 32)    38          ['leaky_re_lu_7[1][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,201,060\n",
      "Trainable params: 2,103,456\n",
      "Non-trainable params: 2,097,604\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Helper function uses `prune_low_magnitude` to make only the \n",
    "# Dense layers train with pruning.\n",
    "def apply_pruning_to_dense(layer):\n",
    "  pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.1, begin_step=0, frequency=100), #Control sparsity\n",
    "      # 'pruning_policy': tfmot.sparsity.keras.PruneForLatencyOnXNNPack()\n",
    "  }\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "  return layer\n",
    "\n",
    "# Use `tf.keras.models.clone_model` to apply `apply_pruning_to_dense` \n",
    "# to the layers of the model.\n",
    "model_for_pruning = tf.keras.models.clone_model(\n",
    "    base_model,\n",
    "    clone_function=apply_pruning_to_dense,\n",
    ")\n",
    "\n",
    "model_for_pruning.summary()\n",
    "# # Define parameters for pruning.\n",
    "# pruning_params = {\n",
    "#       'pruning_policy': tfmot.sparsity.keras.PruneForLatencyOnXNNPack()\n",
    "# }\n",
    "# prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "# # Try to apply pruning wrapper with pruning policy parameter.\n",
    "# model_for_pruning = prune_low_magnitude(base_model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model for pruning.\n",
    "model_for_pruning.compile(optimizer='adam', loss='mse')\n",
    "log_dir = tempfile.mkdtemp()\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    # Log sparsity and other metrics in Tensorboard.\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  5/500 [..............................] - ETA: 17s - loss: 2.7768e-05  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0162s vs `on_train_batch_end` time: 0.0230s). Check your callbacks.\n",
      "500/500 [==============================] - 28s 40ms/step - loss: 9.2697e-06 - val_loss: 8.1164e-06\n",
      "Epoch 2/15\n",
      "500/500 [==============================] - 18s 37ms/step - loss: 7.5190e-06 - val_loss: 8.4994e-06\n",
      "Epoch 3/15\n",
      "500/500 [==============================] - 18s 37ms/step - loss: 7.5571e-06 - val_loss: 7.7751e-06\n",
      "Epoch 4/15\n",
      "500/500 [==============================] - 18s 37ms/step - loss: 7.4059e-06 - val_loss: 7.7134e-06\n",
      "Epoch 5/15\n",
      "500/500 [==============================] - 19s 37ms/step - loss: 7.4055e-06 - val_loss: 7.6242e-06\n",
      "Epoch 6/15\n",
      "500/500 [==============================] - 18s 37ms/step - loss: 7.3249e-06 - val_loss: 7.5572e-06\n",
      "Epoch 7/15\n",
      "500/500 [==============================] - 19s 37ms/step - loss: 7.3411e-06 - val_loss: 7.7668e-06\n",
      "Epoch 8/15\n",
      "500/500 [==============================] - 19s 38ms/step - loss: 7.2710e-06 - val_loss: 7.3989e-06\n",
      "Epoch 9/15\n",
      "500/500 [==============================] - 19s 39ms/step - loss: 7.3210e-06 - val_loss: 7.7685e-06\n",
      "Epoch 10/15\n",
      "500/500 [==============================] - 20s 40ms/step - loss: 7.2512e-06 - val_loss: 7.5092e-06\n",
      "Epoch 11/15\n",
      "500/500 [==============================] - 23s 46ms/step - loss: 7.2768e-06 - val_loss: 7.3225e-06\n",
      "Epoch 12/15\n",
      "500/500 [==============================] - 25s 50ms/step - loss: 7.2348e-06 - val_loss: 7.7498e-06\n",
      "Epoch 13/15\n",
      "500/500 [==============================] - 27s 55ms/step - loss: 7.1996e-06 - val_loss: 7.5313e-06\n",
      "Epoch 14/15\n",
      "500/500 [==============================] - 36s 72ms/step - loss: 7.2281e-06 - val_loss: 7.4471e-06\n",
      "Epoch 15/15\n",
      "500/500 [==============================] - 48s 96ms/step - loss: 7.1934e-06 - val_loss: 7.4538e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e117273370>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_pruning.fit(x_train, x_train,\n",
    "                epochs=15,\n",
    "                batch_size=200,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_val, x_val),\n",
    "                callbacks= callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1/kernel:0: 0.00% sparsity  (0/36)\n",
      "conv2d_1/bias:0: 0.00% sparsity  (0/2)\n",
      "batch_normalization_1/gamma:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_1/beta:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_1/moving_mean:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_1/moving_variance:0: 0.00% sparsity  (0/32)\n",
      "dense_1/kernel:0: 30.00% sparsity  (314573/1048576)\n",
      "dense_1/bias:0: 0.00% sparsity  (0/512)\n",
      "dense_2/kernel:0: 30.00% sparsity  (314573/1048576)\n",
      "dense_2/bias:0: 0.00% sparsity  (0/2048)\n",
      "conv2d_2/kernel:0: 0.00% sparsity  (0/144)\n",
      "conv2d_2/bias:0: 0.00% sparsity  (0/8)\n",
      "batch_normalization_2/gamma:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_2/beta:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_2/moving_mean:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_2/moving_variance:0: 0.00% sparsity  (0/32)\n",
      "conv2d_3/kernel:0: 0.00% sparsity  (0/1152)\n",
      "conv2d_3/bias:0: 0.00% sparsity  (0/16)\n",
      "batch_normalization_3/gamma:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_3/beta:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_3/moving_mean:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_3/moving_variance:0: 0.00% sparsity  (0/32)\n",
      "conv2d_4/kernel:0: 0.00% sparsity  (0/288)\n",
      "conv2d_4/bias:0: 0.00% sparsity  (0/2)\n",
      "batch_normalization_4/gamma:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_4/beta:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_4/moving_mean:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_4/moving_variance:0: 0.00% sparsity  (0/32)\n",
      "conv2d_5/kernel:0: 0.00% sparsity  (0/144)\n",
      "conv2d_5/bias:0: 0.00% sparsity  (0/8)\n",
      "batch_normalization_5/gamma:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_5/beta:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_5/moving_mean:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_5/moving_variance:0: 0.00% sparsity  (0/32)\n",
      "conv2d_6/kernel:0: 0.00% sparsity  (0/1152)\n",
      "conv2d_6/bias:0: 0.00% sparsity  (0/16)\n",
      "batch_normalization_6/gamma:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_6/beta:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_6/moving_mean:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_6/moving_variance:0: 0.00% sparsity  (0/32)\n",
      "conv2d_7/kernel:0: 0.00% sparsity  (0/288)\n",
      "conv2d_7/bias:0: 0.00% sparsity  (0/2)\n",
      "batch_normalization_7/gamma:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_7/beta:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_7/moving_mean:0: 0.00% sparsity  (0/32)\n",
      "batch_normalization_7/moving_variance:0: 0.00% sparsity  (0/32)\n",
      "conv2d_8/kernel:0: 0.00% sparsity  (0/36)\n",
      "conv2d_8/bias:0: 0.00% sparsity  (0/2)\n"
     ]
    }
   ],
   "source": [
    "file = (envir)+'_dim'+str(encoded_dim)\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "# pruned_keras_file = 'optimized_models/%s/pruned_model_%s.h5'%(file, file)\n",
    "# tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "# print('Saved pruned Keras model to:', pruned_keras_file)\n",
    "def print_model_weights_sparsity(model):\n",
    "\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
    "            weights = layer.trainable_weights\n",
    "        else:\n",
    "            weights = layer.weights\n",
    "        for weight in weights:\n",
    "            # ignore auxiliary quantization weights\n",
    "            if \"quantize_layer\" in weight.name:\n",
    "                continue\n",
    "            weight_size = weight.numpy().size\n",
    "            zero_num = np.count_nonzero(weight == 0)\n",
    "            print(\n",
    "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
    "                f\"({zero_num}/{weight_size})\",\n",
    "            )\n",
    "print_model_weights_sparsity(model_for_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpy8b46qxa\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpy8b46qxa\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.EXPERIMENTAL_SPARSITY]\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "# Saving the model.\n",
    "with open('optimized_models/%s/pruned_30_model_%s.tflite'%(file, file), 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned model in Mb: 5.755962371826172\n"
     ]
    }
   ],
   "source": [
    "prune_size = (get_gzipped_model_size('optimized_models/%s/pruned_30_model_%s.tflite'%(file, file)))\n",
    "print(\"pruned model in Mb:\", prune_size / float(2**20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpp1u3b2z1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmpp1u3b2z1\\assets\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmp_9xhjsz_\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Omar\\AppData\\Local\\Temp\\tmp_9xhjsz_\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_and_pruned_tflite_model = converter.convert()\n",
    "\n",
    "# Passing the Keras model to the TF Lite Converter.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "# Using float-16 quantization.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "# Converting the model.\n",
    "pruned_fp16_quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Saving the model.\n",
    "with open('optimized_models/%s/pruned_30_quant_model_%s.tflite'%(file, file), 'wb') as f:\n",
    "  f.write(quantized_and_pruned_tflite_model)\n",
    "with open('optimized_models/%s/pruned_30_fp16_quant_model_%s.tflite'%(file, file), 'wb') as f:\n",
    "  f.write(pruned_fp16_quantized_tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned quant model in Mb: 1.0977869033813477\n"
     ]
    }
   ],
   "source": [
    "prune_quant_size = (get_gzipped_model_size('optimized_models/%s/pruned_30_quant_model_%s.tflite'%(file, file)))\n",
    "prune_fp16_quant_size = (get_gzipped_model_size('optimized_models/%s/pruned_30_fp16_quant_model_%s.tflite'%(file, file)))\n",
    "print(\"pruned quant model in Mb:\", prune_quant_size / float(2**20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "946bca45cd194ef20b20aa2df2b6857f6c4def631856f59c9b0da3a792eb3375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
